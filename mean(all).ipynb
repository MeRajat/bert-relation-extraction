{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Relation extraction with BERT\n\n---\n\nThe goal of this notebook is to show how to use [BERT](https://arxiv.org/abs/1810.04805)\nto [extract relation](https://en.wikipedia.org/wiki/Relationship_extraction) from text.\n\nUsed libraries:\n- [PyTorch](https://pytorch.org/)\n- [PyTorch-Lightning](https://pytorch-lightning.readthedocs.io/en/latest/)\n- [Transformers](https://huggingface.co/transformers/index.html)\n\nUsed datasets:\n- SemEval 2010 Task 8 - [paper](https://arxiv.org/pdf/1911.10422.pdf) - [download](https://github.com/sahitya0000/Relation-Classification/blob/master/corpus/SemEval2010_task8_all_data.zip?raw=true)\n- Google IISc Distant Supervision (GIDS) - [paper](https://arxiv.org/pdf/1804.06987.pdf) - [download](https://drive.google.com/open?id=1gTNAbv8My2QDmP-OHLFtJFlzPDoCG4aI)\n- Riedel's New York Times - [paper](https://www.researchgate.net/publication/220698997_Modeling_Relations_and_Their_Mentions_without_Labeled_Text) - [download](https://drive.google.com/uc?id=1D7bZPvrSAbIPaFSG7ZswYQcPA3tmouCw&export=download)","execution_count":null},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Install dependencies\n\nThis project uses [Python 3.7+](https://www.python.org/downloads/release/python-378/)","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"!pip install requests==2.23.0 numpy==1.18.5 pandas==1.0.3 \\\n    scikit-learn==0.23.1 pytorch-lightning==0.8.4 torch==1.5.1 \\\n    transformers==3.0.2 sklearn==0.0 tqdm==4.45.0 neptune-client==0.4.119 \\\n    matplotlib==3.1.0 scikit-plot==0.3.7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import needed modules","execution_count":null},{"metadata":{"pycharm":{"name":"#%% \n"},"trusted":true},"cell_type":"code","source":"import gc\nimport json\nimport math\nimport os\nimport shutil\nimport zipfile\nfrom abc import ABC, abstractmethod\nfrom scikitplot.metrics import plot_confusion_matrix\nfrom typing import TextIO, Iterable, Tuple\nfrom urllib.parse import urlparse\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nimport torch\nfrom pandas import DataFrame\nfrom pytorch_lightning import LightningModule, seed_everything\nfrom pytorch_lightning import Trainer as LightningTrainer\nfrom pytorch_lightning.logging.neptune import NeptuneLogger\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch import Tensor, nn\nfrom torch.nn import functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom torch.utils.data import DataLoader, IterableDataset\nfrom tqdm.auto import tqdm\nfrom transformers import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define constants","execution_count":null},{"metadata":{"pycharm":{"name":"#%% \n"},"trusted":true},"cell_type":"code","source":"# --- Random seed ---\nSEED = 2020\nseed_everything(SEED)\n\n# --- Neptune logger ---\nNEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiMTU3YTAxMjctYWQwOC00YTU4LTk5Y2ItM2JmNjJmNDJjY2VkIn0=\"\nNEPTUNE_PROJECT_NAME=\"hung/bert-relation-extraction\"\n\n# --- Directory ---\nROOT_DIR = os.path.abspath('.')\nPROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data/processed') \nMETADATA_FILE_NAME = os.path.join(PROCESSED_DATA_DIR, 'metadata.json')\nCHECKPOINT_DIR = os.path.join(ROOT_DIR, 'checkpoint')\n\n# in local environment\nRAW_DATA_DIR =  os.path.join(ROOT_DIR, 'data/raw')\n\n# in Kaggle environment\n# 3 datasets should already been added to the notebook\nRAW_DATA_DIR = os.path.join(ROOT_DIR, '../input')\n\n# --- Datasets ---\nDATASET_MAPPING = {\n    'SemEval2010Task8': {\n        'dir': os.path.join(RAW_DATA_DIR,'semeval2010-task-8'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'SemEval2010_task8_all_data'),\n        'url': 'https://github.com/sahitya0000/Relation-Classification/'\n               'blob/master/corpus/SemEval2010_task8_all_data.zip?raw=true',\n        'fit_in_memory': True\n    },\n    'GIDS': {\n        'dir': os.path.join(RAW_DATA_DIR,'gids-dataset'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'gids_data'),\n        'url': 'https://drive.google.com/uc?id=1gTNAbv8My2QDmP-OHLFtJFlzPDoCG4aI&export=download',\n        'fit_in_memory': True\n    },\n    'NYT': {\n        'dir': os.path.join(RAW_DATA_DIR,'nyt-relation-extraction'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'riedel_data'),\n        'url': 'https://drive.google.com/uc?id=1D7bZPvrSAbIPaFSG7ZswYQcPA3tmouCw&export=download',\n        'fit_in_memory': False\n    }\n}\n\n# change this variable to switch dataset in later tasks\nDATASET_NAME = 'SemEval2010Task8'\n\n# --- BERT ---\nSUB_START_CHAR = '['\nSUB_END_CHAR = ']'\nOBJ_START_CHAR = '{'\nOBJ_END_CHAR = '}'\n\n# --- BERT Model ---\n# See https://huggingface.co/transformers/pretrained_models.html for the full list\nAVAILABLE_PRETRAINED_MODELS = [\n    'distilbert-base-uncased', \n    'distilbert-base-cased', \n    'distilgpt2', \n    'bert-base-uncased',\n    'roberta-base'\n]\n\n# change this variable to switch pretrained language model in later tasks\nPRETRAINED_MODEL = AVAILABLE_PRETRAINED_MODELS[0]\n\n# if e1 is not related to e2, should \"e2 not related to e1\" be added to the trainning set\nADD_REVERSE_RELATIONSHIP = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download data\n\nThis part **CAN BE SKIPPED** if this notebook is running on Kaggle environment since the dataset has already been included.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, we install `gdown` to download files from Google Drive","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install gdown==3.11.1\nimport gdown","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some download util functions:","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"def download_from_url(url: str, save_path: str, chunk_size: int = 2048):\n    with open(save_path, \"wb\") as f:\n        print(f\"Downloading...\\nFrom: {url}\\nTo: {save_path}\")\n        response = requests.get(url, stream=True)\n        for data in tqdm(response.iter_content(chunk_size=chunk_size)):\n            f.write(data)\n\ndef download_from_google_drive(url: str, save_path: str):\n    gdown.download(url, save_path, use_cookies=False)\n\ndef extract_zip(zip_file_path: str, extract_dir: str, remove_zip_file: bool = True):\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n        print(\"Extracting to \" + extract_dir)\n        for member in tqdm(zip_ref.infolist()):\n            zip_ref.extract(member, extract_dir)\n\n    if remove_zip_file:\n        print(\"Removing zip file\")\n        os.unlink(zip_file_path)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"The download function itself:","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"def download(dataset_name: str, dataset_url: str, dataset_dir: str, dataset_extract_dir: str, force_redownload: bool):\n    print(f\"\\n---> Downloading dataset {dataset_name} <---\")\n    \n    # create raw data dir\n    if not os.path.exists(RAW_DATA_DIR):\n        print(\"Creating raw data directory \" + RAW_DATA_DIR)\n        os.makedirs(RAW_DATA_DIR)\n    \n    # check data has been downloaded\n    if os.path.exists(dataset_dir):\n        if force_redownload:\n            print(f\"Removing old raw data {dataset_dir}\")\n            shutil.rmtree(dataset_dir)\n        else:\n            print(f\"Directory {dataset_dir} exists, skip downloading.\")\n            return\n\n\n    # download\n    tmp_file_path = os.path.join(RAW_DATA_DIR, dataset_name + '.zip')\n    if urlparse(dataset_url).netloc == 'drive.google.com':\n        download_from_google_drive(dataset_url, tmp_file_path)\n    else:\n        download_from_url(dataset_url, tmp_file_path)\n\n    # unzip\n    extract_zip(tmp_file_path, RAW_DATA_DIR)\n\n    # rename\n    os.rename(dataset_extract_dir, dataset_dir)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Download all datasets:","execution_count":null},{"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"def download_all_dataset():\n    for dataset_name, dataset_info in DATASET_MAPPING.items():\n        download(\n            dataset_name,\n            dataset_url=dataset_info['url'],\n            dataset_dir=dataset_info['dir'],\n            dataset_extract_dir=dataset_info['extract_dir'],\n            force_redownload=False\n        )\n\ndownload_all_dataset()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Preprocess","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"class AbstractPreprocessor(ABC):\n    DATASET_NAME = ''\n    VAL_DATA_PROPORTION = 0.2\n\n    def __init__(self, tokenizer: PreTrainedTokenizer):\n        self.tokenizer = tokenizer\n        self.SUB_START_ID, self.SUB_END_ID, self.OBJ_START_ID, self.OBJ_END_ID \\\n            = tokenizer.convert_tokens_to_ids([SUB_START_CHAR, SUB_END_CHAR, OBJ_START_CHAR, OBJ_END_CHAR])\n\n    def preprocess_data(self, reprocess: bool):\n        print(f\"\\n---> Preprocessing {self.DATASET_NAME} dataset <---\")\n        \n        # create processed data dir\n        if not os.path.exists(PROCESSED_DATA_DIR):\n            print(\"Creating processed data directory \" + PROCESSED_DATA_DIR)\n            os.makedirs(PROCESSED_DATA_DIR)\n\n        # stop preprocessing if file existed\n        json_file_names = [self.get_json_file_name(k) for k in ('train', 'val', 'test')]\n        existed_files = [fn for fn in json_file_names if os.path.exists(fn)]\n        if existed_files:\n            file_text = \"- \" + \"\\n- \".join(existed_files)\n            if not reprocess:\n                print(\"The following files already exist:\")\n                print(file_text)\n                print(\"Preprocessing is skipped. See option --reprocess.\")\n                return\n            else:\n                print(\"The following files will be overwritten:\")\n                print(file_text)\n\n        self._preprocess_data()\n\n    @abstractmethod\n    def _preprocess_data(self):\n        pass\n\n    def _find_sub_obj_pos(self, input_ids_list: Iterable) -> DataFrame:\n        sub_start_pos = [self._index(s, self.SUB_START_ID) + 1 for s in input_ids_list]\n        sub_end_pos = [self._index(s, self.SUB_END_ID, sub_start_pos[i]) for i, s in enumerate(input_ids_list)]\n        obj_start_pos = [self._index(s, self.OBJ_START_ID) + 1 for s in input_ids_list]\n        obj_end_pos = [self._index(s, self.OBJ_END_ID, obj_start_pos[i]) for i, s in enumerate(input_ids_list)]\n        return DataFrame({\n            'sub_start_pos': sub_start_pos,\n            'sub_end_pos': sub_end_pos,\n            'obj_start_pos': obj_start_pos,\n            'obj_end_pos': obj_end_pos,\n        })\n\n    def _index(self, lst: list, ele: int, start: int = 0) -> int:\n        try:\n            return lst.index(ele, start)\n        except ValueError:\n            return -1\n\n    def _remove_invalid_sentences(self, data: DataFrame) -> DataFrame:\n        seq_max_len = self.tokenizer.model_max_length\n        return data.loc[\n            (data['sub_end_pos'] < seq_max_len)\n            & (data['obj_end_pos'] < seq_max_len)\n            & (data['sub_end_pos'] > -1)\n            & (data['obj_end_pos'] > -1)\n        ]\n\n    def _get_label_mapping(self, le: LabelEncoder):\n        id_to_label = dict(enumerate(le.classes_))\n        label_to_id = {v: k for k, v in id_to_label.items()}\n        return {\n            'id_to_label': id_to_label,\n            'label_to_id': label_to_id\n        }\n\n    def _append_data_to_file(self, data: DataFrame, file: TextIO):\n        lines = \"\"\n        for _, row in data.iterrows():\n            lines += row.to_json() + \"\\n\"\n        file.write(lines)\n\n    def _save_metadata(self, metadata: dict):\n        # create metadata file\n        if not os.path.exists(METADATA_FILE_NAME):\n            print(f\"Create metadata file at {METADATA_FILE_NAME}\")\n            with open(METADATA_FILE_NAME, 'w') as f:\n                f.write(\"{}\\n\")\n\n        # add metadata\n        print(\"Saving metadata\")\n        with open(METADATA_FILE_NAME) as f:\n            root_metadata = json.load(f)\n        with open(METADATA_FILE_NAME, 'w') as f:\n            root_metadata[self.DATASET_NAME] = metadata\n            json.dump(root_metadata, f, indent=4)\n\n    @classmethod\n    def get_json_file_name(cls, key: str) -> str:\n        return os.path.join(PROCESSED_DATA_DIR, f'{cls.DATASET_NAME.lower()}_{key}.json')\n\nclass SemEval2010Task8Preprocessor(AbstractPreprocessor):\n    DATASET_NAME = 'SemEval2010Task8'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'],\n                                       'SemEval2010_task8_training/TRAIN_FILE.TXT')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'],\n                                      'SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT')\n    RAW_TRAIN_DATA_SIZE = 8000\n    RAW_TEST_DATA_SIZE = 2717\n\n    def _preprocess_data(self):\n        print(\"Processing training data\")\n        train_data = self._get_data_from_file(\n            self.RAW_TRAIN_FILE_NAME,\n            self.RAW_TRAIN_DATA_SIZE\n        )\n\n        print(\"Processing test data\")\n        test_data = self._get_data_from_file(\n            self.RAW_TEST_FILE_NAME,\n            self.RAW_TEST_DATA_SIZE\n        )\n\n        print(\"Encoding labels to integers\")\n        le = LabelEncoder()\n        train_data['label'] = le.fit_transform(train_data['label'])\n        test_data['label'] = le.transform(test_data['label'])\n\n        print(\"Splitting train & validate data\")\n        train_data, val_data = train_test_split(train_data, shuffle=True, random_state=SEED)\n\n        print(\"Saving to json files\")\n        with open(self.get_json_file_name('train'), 'w') as f:\n            self._append_data_to_file(train_data, f)\n        with open(self.get_json_file_name('val'), 'w') as f:\n            self._append_data_to_file(val_data, f)\n        with open(self.get_json_file_name('test'), 'w') as f:\n            self._append_data_to_file(test_data, f)\n\n        self._save_metadata({\n            'train_size': len(train_data) ,\n            'val_size': len(val_data),\n            'test_size': len(test_data),\n            **self._get_label_mapping(le)\n        })\n\n    def _get_data_from_file(self, file_name: str, dataset_size: int, reverse: bool = ADD_REVERSE_RELATIONSHIP) -> DataFrame:\n        raw_sentences = []\n        labels = []\n        with open(file_name) as f:\n            for _ in tqdm(range(dataset_size)):\n                sent = f.readline()\n                label, sub, obj = self._process_label(f.readline())\n                labels.append(label)\n                raw_sentences.append(self._process_sentence(sent, sub, obj))\n                if label == 'Other' and reverse:\n                    labels.append(label)\n                    raw_sentences.append(self._process_sentence(sent, obj, sub))\n                f.readline()\n                f.readline()\n        tokens = self.tokenizer(raw_sentences, truncation=True, padding='max_length')\n        data = DataFrame(tokens.data)\n        data['label'] = labels\n        sub_obj_position = self._find_sub_obj_pos(data['input_ids'])\n        data = pd.concat([data, sub_obj_position], axis=1)\n        data = self._remove_invalid_sentences(data)\n        return data\n\n    def _process_sentence(self, sentence: str, sub: int, obj: int) -> str:\n        return sentence.split(\"\\t\")[1][1:-2] \\\n            .replace(f\"<e{sub}>\", SUB_START_CHAR) \\\n            .replace(f\"</e{sub}>\", SUB_END_CHAR) \\\n            .replace(f\"<e{obj}>\", OBJ_START_CHAR) \\\n            .replace(f\"</e{obj}>\", OBJ_END_CHAR)\n\n    def _process_label(self, label: str) -> Tuple[str, int, int]:\n        label = label.strip()\n        if label == 'Other':\n            return label, 1, 2\n        nums = list(filter(str.isdigit, label))\n        return label, int(nums[0]), int(nums[1])\n\nclass LargeDatasetPreprocessor(AbstractPreprocessor):\n    PROCESS_BATCH_SIZE = 2**12\n\n    def _preprocess_data(self):\n        pass\n\n    def _process_batch(self, le: LabelEncoder, in_file: TextIO) -> DataFrame:\n        raw_sentences = []\n        labels = []\n\n        for _ in range(self.PROCESS_BATCH_SIZE):\n            dt = in_file.readline()\n            if dt == \"\": break # EOF\n            dt = json.loads(dt)\n\n            # add subject markup\n            sub = dt['sub']  # TODO keep _ or not?\n            obj = dt['obj']\n            new_sub = SUB_START_CHAR + ' ' + sub.replace(\"_\", \"\") + ' ' + SUB_END_CHAR\n            new_obj = OBJ_START_CHAR + ' ' +  obj.replace(\"_\", \"\") + ' ' + OBJ_END_CHAR\n            self._replace_once(dt['sent'], sub, new_sub)\n            self._replace_once(dt['sent'], obj, new_obj)\n            raw_sentences.append(\" \".join(dt['sent']))\n            labels.append(dt['rel'])\n\n        if not raw_sentences:\n            return DataFrame()\n\n        tokens = self.tokenizer(raw_sentences, truncation=True, padding='max_length')\n        data = DataFrame(tokens.data)\n        data['label'] = le.fit_transform(labels)\n        sub_obj_position = self._find_sub_obj_pos(data['input_ids'])\n        data = pd.concat([data, sub_obj_position], axis=1)\n        data = self._remove_invalid_sentences(data)\n        return data\n\n    def _replace_once(self, arr: list, element, replacement):\n        for i, e in enumerate(arr):\n            if e == element:\n                arr[i] = replacement\n                return\n            if e[:-1] == element and e[-1] in ',.?!;:':\n                arr[i] = replacement + e[-1]\n                return\n\n    def _process_subset(self, le: LabelEncoder, in_file_name, out_file_name, data_size) -> int:\n        total_data_size = 0\n        with open(in_file_name) as in_file, open(out_file_name, 'w') as out_file:\n            batch_count = math.ceil(data_size / self.PROCESS_BATCH_SIZE)\n            for _ in tqdm(range(batch_count)):\n                data = self._process_batch(le, in_file)\n                self._append_data_to_file(data, out_file)\n                total_data_size += len(data)\n        return total_data_size\n\nclass GIDSPreprocessor(LargeDatasetPreprocessor):\n    DATASET_NAME = 'GIDS'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_train.json')\n    RAW_VAL_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_dev.json')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_test.json')\n    TRAIN_SIZE = 11297\n    VAL_SIZE = 1864\n    TEST_SIZE = 5663\n    PROCESS_BATCH_SIZE = 1024\n\n    def _preprocess_data(self):\n        le = LabelEncoder()\n        \n        print(\"Process train dataset\")\n        actual_train_size = self._process_subset(\n            le,\n            self.RAW_TRAIN_FILE_NAME,\n            self.get_json_file_name('train'),\n            self.TRAIN_SIZE\n        )\n\n        print(\"Process val dataset\")\n        actual_val_size = self._process_subset(\n            le,\n            self.RAW_VAL_FILE_NAME,\n            self.get_json_file_name('val'),\n            self.VAL_SIZE\n        )\n        \n        print(\"Process test dataset\")\n        actual_test_size = self._process_subset(\n            le, \n            self.RAW_TEST_FILE_NAME, \n            self.get_json_file_name('test'),\n            self.TEST_SIZE\n        )\n\n        self._save_metadata({\n            'train_size': actual_train_size,\n            'val_size': actual_val_size,\n            'test_size': actual_test_size,\n            **self._get_label_mapping(le)\n        })\n\nclass NYTPreprocessor(LargeDatasetPreprocessor):\n    DATASET_NAME = 'NYT'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['NYT']['dir'], 'riedel_train.json')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['NYT']['dir'], 'riedel_test.json')\n    TRAIN_SIZE = 570084\n    TEST_SIZE = 172448\n    PROCESS_BATCH_SIZE = 4096 * 4\n\n    def _preprocess_data(self):\n        le = LabelEncoder()\n        actual_train_size = 0\n        actual_val_size = 0\n\n        print(\"Process train & val dataset\")\n        batch_count = math.ceil(self.TRAIN_SIZE / self.PROCESS_BATCH_SIZE)\n        with open(self.RAW_TRAIN_FILE_NAME) as in_file,\\\n                open(self.get_json_file_name('train'), 'w') as train_file,\\\n                open(self.get_json_file_name('val'), 'w') as val_file:\n                    for _ in tqdm(range(batch_count)):\n                        data = self._process_batch(le, in_file)\n                        train_data, val_data = train_test_split(data, shuffle=True, random_state=SEED)\n                        self._append_data_to_file(train_data, train_file)\n                        self._append_data_to_file(val_data, val_file)\n                        actual_train_size += len(train_data)\n                        actual_val_size += len(val_data)\n\n        print(\"Process test dataset\")\n        actual_test_size = self._process_subset(\n            le, \n            self.RAW_TEST_FILE_NAME, \n            self.get_json_file_name('test'),\n            self.TEST_SIZE\n        )\n\n        self._save_metadata({\n            'train_size': actual_train_size,\n            'val_size': actual_val_size,\n            'test_size': actual_test_size,\n            **self._get_label_mapping(le)\n        })\n        \n\ndef get_preprocessor_class():\n    return globals()[f'{DATASET_NAME}Preprocessor']\n        \ndef get_preprocessor()-> AbstractPreprocessor:\n    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n    preprocessors_class = get_preprocessor_class()\n    return preprocessors_class(tokenizer)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor = get_preprocessor()\npreprocessor.preprocess_data(reprocess=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Model\n\n### Dataset","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"class GenericDataset(IterableDataset):\n\n    def __init__(self, subset: str, batch_size: int):\n        assert subset in ['train', 'val', 'test']\n            \n        with open(METADATA_FILE_NAME) as f:\n            metadata = json.load(f)\n        self.length = math.ceil(metadata[DATASET_NAME][f'{subset}_size'] / batch_size)\n        \n        preprocessor_class = get_preprocessor_class()\n        self.file = open(preprocessor_class.get_json_file_name(subset))\n\n        self.fit_in_memory = DATASET_MAPPING[DATASET_NAME]['fit_in_memory']\n\n    def __del__(self):\n        self.file.close()\n\n    def __iter__(self):\n        if self.fit_in_memory:\n            lines = self.file.readlines()\n        else:\n            lines = self.file\n\n        def get_data():\n            for line in lines:\n                data = json.loads(line)\n                input_data = {k: torch.tensor(v) for k, v in data.items() if k != 'label'}\n                yield input_data, data['label']\n\n        return get_data()\n    \n    def __len__(self):\n        return self.length","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Torch Lightning Module","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def decay_lr(epoch):\n    return [1, 1, 0.75, 0.5, 0.25, 0.1, 0.075, 0.05, 0.025, 0.01][epoch]\n\ndef get_activation_layer(activate_func_name):\n    return getattr(nn, activate_func_name)()\n\nclass BERTModule(LightningModule):\n\n    def __init__(self, pretrained_language_model, dataset_name, batch_size, learning_rate,\n                 bert_cls_size, bert_entity_size, dropout_p, activation_function, weight_decay):\n        super().__init__()\n        self.save_hyperparameters()\n        self.proposed_answer = None\n        \n        self.language_model = AutoModel.from_pretrained(pretrained_language_model)\n        \n        with open(METADATA_FILE_NAME) as f:\n            num_classes = len(json.load(f)[dataset_name]['id_to_label'])\n        self.linear = nn.Linear(self.language_model.config.hidden_size, num_classes)\n        self.dropout = nn.Dropout(p=self.hparams.dropout_p)\n        self.activate = get_activation_layer(activation_function)\n\n    def train_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('train')\n\n    def val_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('val')\n\n    def test_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('test')\n\n    def __get_dataloader(self, subset: str) -> DataLoader:\n        batch_size = self.hparams.batch_size\n        return DataLoader(\n            GenericDataset(subset, batch_size),\n            batch_size=batch_size,\n            #shuffle=(subset == 'train'),\n            num_workers=1\n        )\n\n    def configure_optimizers(self):\n        optimizer = AdamW(\n            [p for p in self.parameters() if p.requires_grad],\n            lr=self.hparams.learning_rate,\n            weight_decay=self.hparams.weight_decay\n        )\n        scheduler = LambdaLR(optimizer, decay_lr)\n        return [optimizer], [scheduler]\n\n    def forward(self, input_ids, attention_mask, sub_start_pos, sub_end_pos,\n                obj_start_pos, obj_end_pos) -> Tensor:\n        language_model_output, = self.language_model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        _input = self.dropout(torch.mean(language_model_output, dim=1))\n        logits = self.activate(self.linear(_input))\n        return logits\n\n    def training_step(self, batch, batch_nb) -> dict:\n        input_data, label = batch\n        y_hat = self(**input_data)\n\n        loss = F.cross_entropy(y_hat, label)\n        tensorboard_logs = {'train_loss': loss}\n\n        return {'loss': loss, 'log': tensorboard_logs}\n\n    def validation_step(self, batch, batch_nb) -> dict:\n        input_data, label = batch\n        y_hat = self(**input_data)\n\n        loss = F.cross_entropy(y_hat, label)\n\n        y_hat = torch.argmax(y_hat, dim=1)\n\n        return {\n            'y_hat': y_hat,\n            'label': label,\n            'val_loss': loss,\n        }\n\n    def validation_epoch_end(self, outputs) -> dict:\n        losses = torch.stack([x['val_loss'] for x in outputs])\n        avg_val_loss = losses.mean()\n\n        y_hat = torch.cat([x['y_hat'] for x in outputs]).cpu()\n        label = torch.cat([x['label'] for x in outputs]).cpu()\n        fig, ax = plt.subplots(figsize=(16, 12))\n        plot_confusion_matrix(label, y_hat, ax=ax)\n        self.logger.experiment.log_image('val_confusion_matrix', fig)\n\n        logs = {\n            'avg_val_loss': avg_val_loss,\n            'val_acc': torch.tensor(accuracy_score(label, y_hat)),\n            'val_pre_micro': torch.tensor(precision_score(label, y_hat, average='micro')),\n            'val_rec_micro': torch.tensor(recall_score(label, y_hat, average='micro')),\n            'val_f1_micro': torch.tensor(f1_score(label, y_hat, average='micro')),\n            'val_pre_macro': torch.tensor(precision_score(label, y_hat, average='macro')),\n            'val_rec_macro': torch.tensor(recall_score(label, y_hat, average='macro')),\n            'val_f1_macro': torch.tensor(f1_score(label, y_hat, average='macro')),\n        }\n\n        for k, v in logs.items():\n            self.logger.experiment.log_metric(k, v)\n\n        return {'val_loss': avg_val_loss, 'progress_bar': logs}\n\n    def test_step(self, batch, batch_nb) -> dict:\n        input_data, label = batch\n        y_hat = self(**input_data)\n\n        y_hat = torch.argmax(y_hat, dim=1)\n\n        return {\n            'y_hat': y_hat,\n            'label': label,\n        }\n\n\n    def test_epoch_end(self, outputs) -> dict:\n        y_hat = torch.cat([x['y_hat'] for x in outputs]).cpu()\n        label = torch.cat([x['label'] for x in outputs]).cpu()\n\n        fig, ax = plt.subplots(figsize=(16, 12))\n        plot_confusion_matrix(label, y_hat, ax=ax)\n        self.logger.experiment.log_image(f'test_confusion_matrix', fig)\n\n        logs = {\n            'test_acc': torch.tensor(accuracy_score(label, y_hat)),\n            'test_pre_micro': torch.tensor(precision_score(label, y_hat, average='micro')),\n            'test_rec_micro': torch.tensor(recall_score(label, y_hat, average='micro')),\n            'test_f1_micro': torch.tensor(f1_score(label, y_hat, average='micro')),\n            'test_pre_macro': torch.tensor(precision_score(label, y_hat, average='macro')),\n            'test_rec_macro': torch.tensor(recall_score(label, y_hat, average='macro')),\n            'test_f1_macro': torch.tensor(f1_score(label, y_hat, average='macro')),\n        }\n\n        for k, v in logs.items():\n            self.logger.experiment.log_metric(k, v)\n\n        self.proposed_answer = y_hat.cpu().tolist()\n\n        return {'progress_bar': logs}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Claiming back memory & diskspace\n\nSee [this](https://stackoverflow.com/a/61707643/7342188) and [this](https://stackoverflow.com/a/57860310/7342188)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"1 / 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = None\ntrainer = None\ngc.collect()\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlogger = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"pycharm":{"name":"#%%\n"}},"cell_type":"code","source":"try:\n    shutil.rmtree(CHECKPOINT_DIR)\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Logger","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = NeptuneLogger(\n    api_key=NEPTUNE_API_TOKEN,\n    project_name=NEPTUNE_PROJECT_NAME,\n    close_after_fit=False,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trainer","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"GPUS = 1\nMIN_EPOCHS = 1\nMAX_EPOCHS = 5\n\n\ntrainer = LightningTrainer(\n    gpus=GPUS,\n    min_epochs=MIN_EPOCHS,\n    max_epochs=MAX_EPOCHS,\n#     auto_lr_find='learning_rate',\n    default_root_dir=CHECKPOINT_DIR,\n    reload_dataloaders_every_epoch=True, # needed as we loop over a file,\n    deterministic=True,\n    logger=logger\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training\n\nCreate a model object:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nLEARNING_RATE = 2e-05\n\nBERT_CLS_SIZE = None\nBERT_ENTITY_SIZE = None\n\nDROPOUT_P = 0.2\nACTIVATION_FUNCTION = \"Tanh\"\nWEIGHT_DECAY = 0.01 # default = 0.01\n\nmodel = BERTModule(\n    pretrained_language_model=PRETRAINED_MODEL,\n    dataset_name=DATASET_NAME,\n    batch_size=BATCH_SIZE,\n    learning_rate=LEARNING_RATE,\n    bert_cls_size=BERT_CLS_SIZE,\n    bert_entity_size=BERT_ENTITY_SIZE,\n    dropout_p=DROPOUT_P,\n    activation_function=ACTIVATION_FUNCTION,\n    weight_decay=WEIGHT_DECAY\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start training:","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"trainer.fit(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"trainer.test(model)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Run the offical scorer\n\nSome datasets comes with offical scorers. We will run them in this session.","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"class AbstractScorer(ABC):\n    @abstractmethod\n    def score(self, proposed_answer):\n        pass\n\nclass SemEval2010Task8Scorer(AbstractScorer):\n    RESULT_FILE = \"semeval2010_task8_offical_score.txt\"\n    PROPOSED_ANSWER_FILE = \"semeval2010_task8_proposed_answer.txt\"\n    SCORER = \"../input/semeval2010-task-8/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl\"\n    FORMAT_CHECKER = \"../input/semeval2010-task-8/SemEval2010_task8_scorer-v1.2/semeval2010_task8_format_checker.pl\"\n    ANSWER_KEY = \"../input/semeval2010-task-8/SemEval2010_task8_testing_keys/TEST_FILE_KEY.TXT\"\n\n    def score(self, proposed_answer):\n\n        # write test_result to file\n        with open(METADATA_FILE_NAME) as f:\n            metadata = json.load(f)\n            id_to_label = {int(k): v for k, v in metadata[DATASET_NAME]['id_to_label'].items()}\n        i = 8001\n        with open(self.PROPOSED_ANSWER_FILE, \"w\") as f:\n            for r in proposed_answer:\n                f.write(f\"{i}\\t{id_to_label[r]}\\n\")\n                i += 1\n\n        # call the official scorer\n        os.system(f\"perl {self.FORMAT_CHECKER} {self.PROPOSED_ANSWER_FILE}\")\n        os.system(f\"perl {self.SCORER} {self.PROPOSED_ANSWER_FILE} {self.ANSWER_KEY} > {self.RESULT_FILE}\")\n\n        # log the official score\n        with open(self.RESULT_FILE) as f:\n            result = f.read()\n            print(result)\n        logger.experiment.log_artifact(self.RESULT_FILE)\n\ndef get_offical_scorer(dataset_name: str) -> AbstractScorer:\n    return globals()[dataset_name + \"Scorer\"]()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"scorer = get_offical_scorer(DATASET_NAME)\nscorer.score(model.proposed_answer)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Clean up\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logger.experiment.stop()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}