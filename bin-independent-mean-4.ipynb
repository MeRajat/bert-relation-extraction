{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Relation extraction with BERT\n\n---\n\nThe goal of this notebook is to show how to use [BERT](https://arxiv.org/abs/1810.04805)\nto [extract relation](https://en.wikipedia.org/wiki/Relationship_extraction) from text.\n\nUsed libraries:\n- [PyTorch](https://pytorch.org/)\n- [PyTorch-Lightning](https://pytorch-lightning.readthedocs.io/en/latest/)\n- [Transformers](https://huggingface.co/transformers/index.html)\n\nUsed datasets:\n- SemEval 2010 Task 8 - [paper](https://arxiv.org/pdf/1911.10422.pdf) - [download](https://github.com/sahitya0000/Relation-Classification/blob/master/corpus/SemEval2010_task8_all_data.zip?raw=true)\n- Google IISc Distant Supervision (GIDS) - [paper](https://arxiv.org/pdf/1804.06987.pdf) - [download](https://drive.google.com/open?id=1gTNAbv8My2QDmP-OHLFtJFlzPDoCG4aI)\n- Riedel's New York Times - [paper](https://www.researchgate.net/publication/220698997_Modeling_Relations_and_Their_Mentions_without_Labeled_Text) - [download](https://drive.google.com/uc?id=1D7bZPvrSAbIPaFSG7ZswYQcPA3tmouCw&export=download)"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "## Install dependencies\n\nThis project uses [Python 3.7+](https://www.python.org/downloads/release/python-378/)"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "!pip install requests==2.23.0 numpy==1.18.5 pandas==1.0.3 \\\n    scikit-learn==0.23.1 pytorch-lightning==0.8.4 torch==1.5.1 \\\n    transformers==3.0.2 sklearn==0.0 tqdm==4.45.0 neptune-client==0.4.119 \\\n    matplotlib==3.1.0 scikit-plot==0.3.7",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": "Requirement already satisfied: requests==2.23.0 in /opt/conda/lib/python3.7/site-packages (2.23.0)\nRequirement already satisfied: numpy==1.18.5 in /opt/conda/lib/python3.7/site-packages (1.18.5)\nRequirement already satisfied: pandas==1.0.3 in /opt/conda/lib/python3.7/site-packages (1.0.3)\nRequirement already satisfied: scikit-learn==0.23.1 in /opt/conda/lib/python3.7/site-packages (0.23.1)\nCollecting pytorch-lightning==0.8.4\n  Downloading pytorch_lightning-0.8.4-py3-none-any.whl (304 kB)\n\u001B[K     |████████████████████████████████| 304 kB 2.8 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: torch==1.5.1 in /opt/conda/lib/python3.7/site-packages (1.5.1)\nCollecting transformers==3.0.2\n  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n\u001B[K     |████████████████████████████████| 769 kB 12.3 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: sklearn==0.0 in /opt/conda/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: tqdm==4.45.0 in /opt/conda/lib/python3.7/site-packages (4.45.0)\nCollecting neptune-client==0.4.119\n  Downloading neptune-client-0.4.119.tar.gz (90 kB)\n\u001B[K     |████████████████████████████████| 90 kB 5.2 MB/s  eta 0:00:01\n\u001B[?25hCollecting matplotlib==3.1.0\n  Downloading matplotlib-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n\u001B[K     |████████████████████████████████| 13.1 MB 13.0 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: scikit-plot==0.3.7 in /opt/conda/lib/python3.7/site-packages (0.3.7)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.23.0) (1.24.3)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3) (2019.3)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3) (2.8.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.1) (0.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.1) (2.1.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.4.1)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==0.8.4) (5.3.1)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==0.8.4) (0.18.2)\nRequirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==0.8.4) (2.2.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (20.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.0.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.43)\nCollecting tokenizers==0.8.1.rc1\n  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001B[K     |████████████████████████████████| 3.0 MB 26.5 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.91)\nCollecting bravado\n  Downloading bravado-10.6.2-py2.py3-none-any.whl (37 kB)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (7.1.1)\nCollecting py3nvml\n  Downloading py3nvml-0.2.6-py3-none-any.whl (55 kB)\n\u001B[K     |████████████████████████████████| 55 kB 2.8 MB/s  eta 0:00:01\n\u001B[?25hRequirement already satisfied: oauthlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (3.0.1)\nRequirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (7.2.0)\nRequirement already satisfied: PyJWT in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (1.7.1)\nRequirement already satisfied: requests-oauthlib>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (1.2.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (1.14.0)\nRequirement already satisfied: websocket-client>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (0.57.0)\nRequirement already satisfied: GitPython>=2.0.8 in /opt/conda/lib/python3.7/site-packages (from neptune-client==0.4.119) (3.1.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.1.0) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.1.0) (1.2.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.1.0) (2.4.7)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (1.14.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (46.1.3.post20200325)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (0.9.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (1.30.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (1.0.1)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (0.34.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (1.7.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (0.4.1)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (3.12.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning==0.8.4) (3.2.1)\nCollecting monotonic\n  Downloading monotonic-1.5-py2.py3-none-any.whl (5.3 kB)\nCollecting bravado-core>=5.16.1\n  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n\u001B[K     |████████████████████████████████| 67 kB 4.4 MB/s  eta 0:00:01\n\u001B[?25hRequirement already satisfied: simplejson in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client==0.4.119) (3.17.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client==0.4.119) (3.7.4.1)\nCollecting msgpack-python\n  Downloading msgpack-python-0.5.6.tar.gz (138 kB)\n\u001B[K     |████████████████████████████████| 138 kB 53.0 MB/s eta 0:00:01\n\u001B[?25hCollecting xmltodict\n  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=2.0.8->neptune-client==0.4.119) (4.0.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.4) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.4) (3.1.1)\n",
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.4) (4.0)\nRequirement already satisfied: jsonschema[format]>=2.5.1 in /opt/conda/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (3.2.0)\nCollecting jsonref\n  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\nRequirement already satisfied: msgpack>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (1.0.0)\nCollecting swagger-spec-validator>=2.0.1\n  Downloading swagger_spec_validator-2.7.3-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client==0.4.119) (3.0.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.4) (0.4.8)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (0.16.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (1.6.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (19.3.0)\nCollecting jsonpointer>1.13; extra == \"format\"\n  Downloading jsonpointer-2.0-py2.py3-none-any.whl (7.6 kB)\nCollecting strict-rfc3339; extra == \"format\"\n  Downloading strict-rfc3339-0.7.tar.gz (17 kB)\nCollecting rfc3987; extra == \"format\"\n  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\nCollecting webcolors; extra == \"format\"\n  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.119) (3.1.0)\nBuilding wheels for collected packages: neptune-client, msgpack-python, strict-rfc3339\n  Building wheel for neptune-client (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for neptune-client: filename=neptune_client-0.4.119-py2.py3-none-any.whl size=150019 sha256=ef6e66f6c096061688e6a39ae8b0c18255982ada94ebc878a25b3f7ab9ced47f\n  Stored in directory: /root/.cache/pip/wheels/64/3b/7e/69f84d99e2109788f757ef707b3ea51921f16891e42929eb31\n  Building wheel for msgpack-python (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for msgpack-python: filename=msgpack_python-0.5.6-cp37-cp37m-linux_x86_64.whl size=302588 sha256=63336e94e4351fcc0ecd8729e53d572e4171912db3e38b981872260a5fe7d174\n  Stored in directory: /root/.cache/pip/wheels/f8/6c/02/92ebc97f3b99ad5bfc675be2c513f9cb3504fdbe338314f377\n  Building wheel for strict-rfc3339 (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-py3-none-any.whl size=18119 sha256=0df158242dbee910765aefba18eecd79de9581b822f17d45efcb00b99e6da1fb\n  Stored in directory: /root/.cache/pip/wheels/f3/1d/9f/2a74caecb81b8beb9a4fbe1754203d4b7cf42ef5d39e0d2311\nSuccessfully built neptune-client msgpack-python strict-rfc3339\n\u001B[31mERROR: plotnine 0.7.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001B[0m\n\u001B[31mERROR: pandas-profiling 2.6.0 has requirement matplotlib>=3.2.0, but you'll have matplotlib 3.1.0 which is incompatible.\u001B[0m\n\u001B[31mERROR: osmnx 0.15.1 has requirement geopandas>=0.7, but you'll have geopandas 0.6.3 which is incompatible.\u001B[0m\n\u001B[31mERROR: osmnx 0.15.1 has requirement matplotlib>=3.2, but you'll have matplotlib 3.1.0 which is incompatible.\u001B[0m\n\u001B[31mERROR: mizani 0.7.1 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001B[0m\n\u001B[31mERROR: hypertools 0.6.2 has requirement scikit-learn<0.22,>=0.19.1, but you'll have scikit-learn 0.23.1 which is incompatible.\u001B[0m\n\u001B[31mERROR: allennlp 1.0.0 has requirement transformers<2.12,>=2.9, but you'll have transformers 3.0.2 which is incompatible.\u001B[0m\nInstalling collected packages: pytorch-lightning, tokenizers, transformers, monotonic, jsonref, swagger-spec-validator, bravado-core, msgpack-python, bravado, xmltodict, py3nvml, neptune-client, matplotlib, jsonpointer, strict-rfc3339, rfc3987, webcolors\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.7.0\n    Uninstalling tokenizers-0.7.0:\n      Successfully uninstalled tokenizers-0.7.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 2.11.0\n    Uninstalling transformers-2.11.0:\n      Successfully uninstalled transformers-2.11.0\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.2.1\n    Uninstalling matplotlib-3.2.1:\n      Successfully uninstalled matplotlib-3.2.1\nSuccessfully installed bravado-10.6.2 bravado-core-5.17.0 jsonpointer-2.0 jsonref-0.2 matplotlib-3.1.0 monotonic-1.5 msgpack-python-0.5.6 neptune-client-0.4.119 py3nvml-0.2.6 pytorch-lightning-0.8.4 rfc3987-1.3.8 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 tokenizers-0.8.1rc1 transformers-3.0.2 webcolors-1.11.1 xmltodict-0.12.0\n\u001B[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import needed modules"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "import gc\nimport json\nimport math\nimport os\nimport shutil\nimport zipfile\nfrom abc import ABC, abstractmethod\nfrom collections import OrderedDict\nfrom typing import TextIO, Iterable, Tuple\nfrom urllib.parse import urlparse\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport requests\nimport torch\nfrom matplotlib.figure import Figure\nfrom pandas import DataFrame\nfrom pytorch_lightning import LightningModule, seed_everything\nfrom pytorch_lightning import Trainer as LightningTrainer\nfrom pytorch_lightning.logging.neptune import NeptuneLogger\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, \\\n    roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import column_or_1d\nfrom torch import Tensor, nn\nfrom torch.nn import functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom torch.utils.data import DataLoader, IterableDataset\nfrom tqdm.auto import tqdm\nfrom transformers import *",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
     "name": "stderr"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define constants"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "# --- Random seed ---\nSEED = 2020\nseed_everything(SEED)\n\n# --- Neptune logger ---\nNEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiMTU3YTAxMjctYWQwOC00YTU4LTk5Y2ItM2JmNjJmNDJjY2VkIn0=\"\nNEPTUNE_PROJECT_NAME=\"hung/bert-relation-extraction\"\n\n# --- Directory ---\nROOT_DIR = os.path.abspath('.')\nPROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data/processed') \nMETADATA_FILE_NAME = os.path.join(PROCESSED_DATA_DIR, 'metadata.json')\nCHECKPOINT_DIR = os.path.join(ROOT_DIR, 'checkpoint')\n\nKAGGLE_ENV = bool(os.getenv(\"KAGGLE_URL_BASE\"))\nLOCAL_ENV = not KAGGLE_ENV\nif KAGGLE_ENV:\n    # in Kaggle environment\n    # 3 datasets should already been added to the notebook\n    RAW_DATA_DIR = os.path.join(ROOT_DIR, '../input')\nelse:\n    # in local environment\n    RAW_DATA_DIR =  os.path.join(ROOT_DIR, 'data/raw')\n\n# --- Datasets ---\nDATASET_MAPPING = {\n    'SemEval2010Task8': {\n        'dir': os.path.join(RAW_DATA_DIR,'semeval2010-task-8'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'SemEval2010_task8_all_data'),\n        'url': 'https://github.com/sahitya0000/Relation-Classification/'\n               'blob/master/corpus/SemEval2010_task8_all_data.zip?raw=true',\n        'fit_in_memory': True\n    },\n    'GIDS': {\n        'dir': os.path.join(RAW_DATA_DIR,'gids-dataset'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'gids_data'),\n        'url': 'https://drive.google.com/uc?id=1gTNAbv8My2QDmP-OHLFtJFlzPDoCG4aI&export=download',\n        'fit_in_memory': True\n    },\n    'NYT': {\n        'dir': os.path.join(RAW_DATA_DIR,'nyt-relation-extraction'),\n        'extract_dir': os.path.join(RAW_DATA_DIR, 'riedel_data'),\n        'url': 'https://drive.google.com/uc?id=1D7bZPvrSAbIPaFSG7ZswYQcPA3tmouCw&export=download',\n        'fit_in_memory': False\n    }\n}\n\n# change this variable to switch dataset in later tasks\nDATASET_NAME = 'SemEval2010Task8'\n\n# --- BERT ---\nSUB_START_CHAR = '['\nSUB_END_CHAR = ']'\nOBJ_START_CHAR = '{'\nOBJ_END_CHAR = '}'\n\n# --- BERT Model ---\n# See https://huggingface.co/transformers/pretrained_models.html for the full list\nAVAILABLE_PRETRAINED_MODELS = [\n    'distilbert-base-uncased', \n    'distilbert-base-cased', \n    'distilgpt2', \n    'bert-base-uncased',\n    'roberta-base'\n]\n\n# change this variable to switch pretrained language model in later tasks\nPRETRAINED_MODEL = AVAILABLE_PRETRAINED_MODELS[0]\n\n# if e1 is not related to e2, should \"e2 not related to e1\" be added to the training set\nADD_REVERSE_RELATIONSHIP = False",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download data\n\nThis part **CAN BE SKIPPED** if this notebook is running on Kaggle environment since the dataset has already been included."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we install `gdown` to download files from Google Drive"
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "!if [ -z \"KAGGLE_URL_BASE\" ]; then pip install gdown==3.11.1 ; else echo \"gdown is not installed\" ;  fi\n\nif LOCAL_ENV:\n    import gdown\nelse:\n    print(\"gdown is not imported\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Some download util functions:"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "def download_from_url(url: str, save_path: str, chunk_size: int = 2048):\n    with open(save_path, \"wb\") as f:\n        print(f\"Downloading...\\nFrom: {url}\\nTo: {save_path}\")\n        response = requests.get(url, stream=True)\n        for data in tqdm(response.iter_content(chunk_size=chunk_size)):\n            f.write(data)\n\ndef download_from_google_drive(url: str, save_path: str):\n    gdown.download(url, save_path, use_cookies=False)\n\ndef extract_zip(zip_file_path: str, extract_dir: str, remove_zip_file: bool = True):\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n        print(\"Extracting to \" + extract_dir)\n        for member in tqdm(zip_ref.infolist()):\n            zip_ref.extract(member, extract_dir)\n\n    if remove_zip_file:\n        print(\"Removing zip file\")\n        os.unlink(zip_file_path)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "The download function itself:"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "def download(dataset_name: str, dataset_url: str, dataset_dir: str, dataset_extract_dir: str, force_redownload: bool):\n    print(f\"\\n---> Downloading dataset {dataset_name} <---\")\n    \n    # create raw data dir\n    if not os.path.exists(RAW_DATA_DIR):\n        print(\"Creating raw data directory \" + RAW_DATA_DIR)\n        os.makedirs(RAW_DATA_DIR)\n    \n    # check data has been downloaded\n    if os.path.exists(dataset_dir):\n        if force_redownload:\n            print(f\"Removing old raw data {dataset_dir}\")\n            shutil.rmtree(dataset_dir)\n        else:\n            print(f\"Directory {dataset_dir} exists, skip downloading.\")\n            return\n\n\n    # download\n    tmp_file_path = os.path.join(RAW_DATA_DIR, dataset_name + '.zip')\n    if urlparse(dataset_url).netloc == 'drive.google.com':\n        download_from_google_drive(dataset_url, tmp_file_path)\n    else:\n        download_from_url(dataset_url, tmp_file_path)\n\n    # unzip\n    extract_zip(tmp_file_path, RAW_DATA_DIR)\n\n    # rename\n    os.rename(dataset_extract_dir, dataset_dir)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "Download all datasets:"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "def download_all_dataset():\n    for dataset_name, dataset_info in DATASET_MAPPING.items():\n        download(\n            dataset_name,\n            dataset_url=dataset_info['url'],\n            dataset_dir=dataset_info['dir'],\n            dataset_extract_dir=dataset_info['extract_dir'],\n            force_redownload=False\n        )\n\nif LOCAL_ENV:\n    download_all_dataset()\nelse:\n    print(\"Skip downloading\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "## Preprocess\n\nFirst, we define a custom label encoder. What this label encoder offers but `sklearn.preprocessing.LabelEncoder` fails\nto provide:\n- Order preservation: labels will be encoded in order they appear in the dataset. Labels appears earlier will have\n  smaller id. We need this to ensure the `no relation` class always becomes `0`\n- Multiple fit: `sklearn.preprocessing.LabelEncoder` forgets what is fit in the last time `fit` is called. This is useful\n  when we process large dataset in batches."
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "class OrdinalLabelEncoder:\n    def __init__(self, init_labels=None):\n        if init_labels is None:\n            init_labels = []\n        self.mapping = OrderedDict({l: i for i, l in enumerate(init_labels)})\n\n    @property\n    def classes_(self):\n        return list(self.mapping.keys())\n\n    def fit_transform(self, y):\n        return self.fit(y).transform(y)\n\n    def fit(self, y):\n        y = column_or_1d(y, warn=True)\n        new_classes = pd.Series(y).unique()\n        for cls in new_classes:\n            if cls not in self.mapping:\n                self.mapping[cls] = len(self.mapping)\n        return self\n\n    def transform(self, y):\n        y = column_or_1d(y, warn=True)\n        return [self.mapping[value] for value in y]\n    ",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "Preprocessor classes:"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": true
   },
   "cell_type": "code",
   "source": "class AbstractPreprocessor(ABC):\n    DATASET_NAME = ''\n    VAL_DATA_PROPORTION = 0.2\n    NO_RELATION_LABEL = ''\n\n    def __init__(self, tokenizer: PreTrainedTokenizer):\n        self.tokenizer = tokenizer\n        self.SUB_START_ID, self.SUB_END_ID, self.OBJ_START_ID, self.OBJ_END_ID \\\n            = tokenizer.convert_tokens_to_ids([SUB_START_CHAR, SUB_END_CHAR, OBJ_START_CHAR, OBJ_END_CHAR])\n\n    def preprocess_data(self, reprocess: bool):\n        print(f\"\\n---> Preprocessing {self.DATASET_NAME} dataset <---\")\n        \n        # create processed data dir\n        if not os.path.exists(PROCESSED_DATA_DIR):\n            print(\"Creating processed data directory \" + PROCESSED_DATA_DIR)\n            os.makedirs(PROCESSED_DATA_DIR)\n\n        # stop preprocessing if file existed\n        json_file_names = [self.get_dataset_file_name(k) for k in ('train', 'val', 'test')]\n        existed_files = [fn for fn in json_file_names if os.path.exists(fn)]\n        if existed_files:\n            file_text = \"- \" + \"\\n- \".join(existed_files)\n            if not reprocess:\n                print(\"The following files already exist:\")\n                print(file_text)\n                print(\"Preprocessing is skipped. See option --reprocess.\")\n                return\n            else:\n                print(\"The following files will be overwritten:\")\n                print(file_text)\n\n        self._preprocess_data()\n        self._create_secondary_data_files()\n\n        print(\"---> Done ! <---\")\n\n    @abstractmethod\n    def _preprocess_data(self):\n        pass\n\n    def _create_secondary_data_files(self):\n        \"\"\"\n        From the primary data file, create a data file with binary labels\n        and a data file with only sentences classified as \"related\"\n        \"\"\"\n\n        with open(METADATA_FILE_NAME) as f:\n            root_metadata = json.load(f)\n            metadata = root_metadata[self.DATASET_NAME]\n\n        related_only_count = {\n            'train': 0,\n            'val': 0,\n            'test': 0,\n        }\n\n        for key in ['train', 'test', 'val']:\n            print(f\"Creating secondary files for {key} data\")\n\n            origin_file = open(self.get_dataset_file_name(key))\n            bin_file = open(self.get_dataset_file_name(f'{key}_binary'), \"w\")\n            related_file = open(self.get_dataset_file_name(f'{key}_related_only'), \"w\")\n\n            total = metadata[f'{key}_size']\n\n            for line in tqdm(origin_file, total=total):\n                data = json.loads(line)\n                if data['label'] != 0:\n                    related_only_count[key] += 1\n                    data['label'] -= 1 # label in \"related_only\" files is 1 less than the original label\n                    related_file.write(json.dumps(data) + \"\\n\")\n                    data['label'] = 1 # in binary dataset, all \"related\" classes have label 1\n                    bin_file.write(json.dumps(data) + \"\\n\")\n                else:\n                    bin_file.write(json.dumps(data) + \"\\n\")\n\n            origin_file.close()\n            bin_file.close()\n            related_file.close()\n\n        print(\"Updating metadata.json\")\n        for key in ['train', 'test', 'val']:\n            metadata[f'{key}_related_only_size'] = related_only_count[key]\n        root_metadata[self.DATASET_NAME] = metadata\n        with open(METADATA_FILE_NAME, \"w\") as f:\n            json.dump(root_metadata, f, indent=4)\n\n    def _find_sub_obj_pos(self, input_ids_list: Iterable) -> DataFrame:\n        \"\"\"\n        Find subject and object position in a sentence\n        \"\"\"\n        sub_start_pos = [self._index(s, self.SUB_START_ID) + 1 for s in input_ids_list]\n        sub_end_pos = [self._index(s, self.SUB_END_ID, sub_start_pos[i]) for i, s in enumerate(input_ids_list)]\n        obj_start_pos = [self._index(s, self.OBJ_START_ID) + 1 for s in input_ids_list]\n        obj_end_pos = [self._index(s, self.OBJ_END_ID, obj_start_pos[i]) for i, s in enumerate(input_ids_list)]\n        return DataFrame({\n            'sub_start_pos': sub_start_pos,\n            'sub_end_pos': sub_end_pos,\n            'obj_start_pos': obj_start_pos,\n            'obj_end_pos': obj_end_pos,\n        })\n\n    @staticmethod\n    def _index(lst: list, ele: int, start: int = 0) -> int:\n        \"\"\"\n        Find an element in a list. Returns -1 if not found instead of raising an exception.\n        \"\"\"\n        try:\n            return lst.index(ele, start)\n        except ValueError:\n            return -1\n\n    def _remove_invalid_sentences(self, data: DataFrame) -> DataFrame:\n        \"\"\"\n        Remove sentences without subject/object or whose subject/object\n        is beyond the maximum length the model supports\n        \"\"\"\n        seq_max_len = self.tokenizer.model_max_length\n        return data.loc[\n            (data['sub_end_pos'] < seq_max_len)\n            & (data['obj_end_pos'] < seq_max_len)\n            & (data['sub_end_pos'] > -1)\n            & (data['obj_end_pos'] > -1)\n        ]\n\n    @staticmethod\n    def _get_label_mapping(le: LabelEncoder):\n        \"\"\"\n        Returns a mapping from id to label and vise versa from the label encoder\n        \"\"\"\n        # all labels\n        id_to_label = dict(enumerate(le.classes_))\n        label_to_id = {v: k for k, v in id_to_label.items()}\n\n        # for the related_only dataset\n        # ignore id 0, which represent no relation\n        id_to_label_related_only = {k - 1: v for k, v in id_to_label.items() if k != 0}\n        label_to_id_related_only = {v: k for k, v in id_to_label_related_only.items()}\n\n        return {\n            'id_to_label': id_to_label,\n            'label_to_id': label_to_id,\n            'id_to_label_related_only': id_to_label_related_only,\n            'label_to_id_related_only': label_to_id_related_only,            \n        }\n\n    @staticmethod\n    def _append_data_to_file(data: DataFrame, file: TextIO):\n        \"\"\"Append data from a dataframe to an opened file\"\"\"\n        lines = \"\"\n        for _, row in data.iterrows():\n            lines += row.to_json() + \"\\n\"\n        file.write(lines)\n\n    def _save_metadata(self, metadata: dict):\n        \"\"\"Save metadata to metadata.json\"\"\"\n        # create metadata file\n        if not os.path.exists(METADATA_FILE_NAME):\n            print(f\"Create metadata file at {METADATA_FILE_NAME}\")\n            with open(METADATA_FILE_NAME, 'w') as f:\n                f.write(\"{}\\n\")\n\n        # add metadata\n        print(\"Saving metadata\")\n        with open(METADATA_FILE_NAME) as f:\n            root_metadata = json.load(f)\n        with open(METADATA_FILE_NAME, 'w') as f:\n            root_metadata[self.DATASET_NAME] = metadata\n            json.dump(root_metadata, f, indent=4)\n\n    def _get_label_encoder(self) -> OrdinalLabelEncoder:\n        \"\"\"\n        Factory method for label encoder\n        Ensure that \"no relation\" has id 0\n        \"\"\"\n        return OrdinalLabelEncoder([self.NO_RELATION_LABEL])\n\n    @classmethod\n    def get_dataset_file_name(cls, key: str) -> str:\n        return os.path.join(PROCESSED_DATA_DIR, f'{cls.DATASET_NAME.lower()}_{key}.json')\n\n\nclass SemEval2010Task8Preprocessor(AbstractPreprocessor):\n    DATASET_NAME = 'SemEval2010Task8'\n    NO_RELATION_LABEL = 'Other'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'],\n                                       'SemEval2010_task8_training/TRAIN_FILE.TXT')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'],\n                                      'SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT')\n    RAW_TRAIN_DATA_SIZE = 8000\n    RAW_TEST_DATA_SIZE = 2717\n\n    def _preprocess_data(self):\n        print(\"Processing training data\")\n        train_data = self._get_data_from_file(\n            self.RAW_TRAIN_FILE_NAME,\n            self.RAW_TRAIN_DATA_SIZE\n        )\n\n        print(\"Processing test data\")\n        test_data = self._get_data_from_file(\n            self.RAW_TEST_FILE_NAME,\n            self.RAW_TEST_DATA_SIZE\n        )\n\n        print(\"Encoding labels to integers\")\n        le = self._get_label_encoder()\n        train_data['label'] = le.fit_transform(train_data['label'])\n        test_data['label'] = le.transform(test_data['label'])\n\n        print(\"Splitting train & validate data\")\n        train_data, val_data = train_test_split(train_data, shuffle=True, random_state=SEED)\n\n        print(\"Saving to json files\")\n        with open(self.get_dataset_file_name('train'), 'w') as f:\n            self._append_data_to_file(train_data, f)\n        with open(self.get_dataset_file_name('val'), 'w') as f:\n            self._append_data_to_file(val_data, f)\n        with open(self.get_dataset_file_name('test'), 'w') as f:\n            self._append_data_to_file(test_data, f)\n\n        self._save_metadata({\n            'train_size': len(train_data),\n            'val_size': len(val_data),\n            'test_size': len(test_data),\n            'no_relation_label': self.NO_RELATION_LABEL,\n            **self._get_label_mapping(le)\n        })\n\n    def _get_data_from_file(self, file_name: str, dataset_size: int, reverse: bool = ADD_REVERSE_RELATIONSHIP) -> DataFrame:\n        raw_sentences = []\n        labels = []\n        with open(file_name) as f:\n            for _ in tqdm(range(dataset_size)):\n                sent = f.readline()\n                label, sub, obj = self._process_label(f.readline())\n                labels.append(label)\n                raw_sentences.append(self._process_sentence(sent, sub, obj))\n                if label == 'Other' and reverse:\n                    labels.append(label)\n                    raw_sentences.append(self._process_sentence(sent, obj, sub))\n                f.readline()\n                f.readline()\n        tokens = self.tokenizer(raw_sentences, truncation=True, padding='max_length')\n        data = DataFrame(tokens.data)\n        data['label'] = labels\n        sub_obj_position = self._find_sub_obj_pos(data['input_ids'])\n        data = pd.concat([data, sub_obj_position], axis=1)\n        data = self._remove_invalid_sentences(data)\n        return data\n\n    @staticmethod\n    def _process_sentence(sentence: str, sub: int, obj: int) -> str:\n        return sentence.split(\"\\t\")[1][1:-2] \\\n            .replace(f\"<e{sub}>\", SUB_START_CHAR) \\\n            .replace(f\"</e{sub}>\", SUB_END_CHAR) \\\n            .replace(f\"<e{obj}>\", OBJ_START_CHAR) \\\n            .replace(f\"</e{obj}>\", OBJ_END_CHAR)\n\n    @staticmethod\n    def _process_label(label: str) -> Tuple[str, int, int]:\n        label = label.strip()\n        if label == 'Other':\n            return label, 1, 2\n        nums = list(filter(str.isdigit, label))\n        return label, int(nums[0]), int(nums[1])\n\n\nclass GID_NYT_BasePreprocessor(AbstractPreprocessor):\n    \"\"\"Base preprocessor class for GIDS and NYT datasets\"\"\"\n\n    PROCESS_BATCH_SIZE = 2**12\n    NO_RELATION_LABEL = 'NA'\n\n    def _preprocess_data(self):\n        pass\n\n    def _process_batch(self, le: LabelEncoder, in_file: TextIO) -> DataFrame:\n        \"\"\"\n        Process one batch\n        \"\"\"\n        raw_sentences = []\n        labels = []\n\n        for _ in range(self.PROCESS_BATCH_SIZE):\n            dt = in_file.readline()\n            if dt == \"\": break # EOF\n            dt = json.loads(dt)\n\n            # add subject markup\n            sub = dt['sub']  # TODO keep _ or not?\n            obj = dt['obj']\n            new_sub = SUB_START_CHAR + ' ' + sub.replace(\"_\", \"\") + ' ' + SUB_END_CHAR\n            new_obj = OBJ_START_CHAR + ' ' +  obj.replace(\"_\", \"\") + ' ' + OBJ_END_CHAR\n            self._replace_word_once(dt['sent'], sub, new_sub)\n            self._replace_word_once(dt['sent'], obj, new_obj)\n            raw_sentences.append(\" \".join(dt['sent']))\n            labels.append(dt['rel'])\n\n        if not raw_sentences:\n            return DataFrame()\n\n        tokens = self.tokenizer(raw_sentences, truncation=True, padding='max_length')\n        data = DataFrame(tokens.data)\n        data['label'] = le.fit_transform(labels)\n        sub_obj_position = self._find_sub_obj_pos(data['input_ids'])\n        data = pd.concat([data, sub_obj_position], axis=1)\n        data = self._remove_invalid_sentences(data)\n        return data\n\n    @staticmethod\n    def _replace_word_once(arr: list, element: str, replacement: str):\n        \"\"\"\n        Replace a word in a list of words by another\n        Also take care of punctuations\n        \"\"\"\n        for i, e in enumerate(arr):\n            # exact match\n            if e == element:\n                arr[i] = replacement\n                return\n            # check for elements that ends with a special character\n            if e[:-1] == element and e[-1] in ',.?!;:':\n                arr[i] = replacement + e[-1]\n                return\n\n    def _process_file(self, le: LabelEncoder, in_file_name: str, out_file_name: str, data_size: int) -> int:\n        \"\"\"\n        Process a file in batches\n        Return the total data size\n        \"\"\"\n        total_data_size = 0\n        batch_count = math.ceil(data_size / self.PROCESS_BATCH_SIZE)\n\n        with open(in_file_name) as in_file, open(out_file_name, 'w') as out_file:\n            for _ in tqdm(range(batch_count)):\n                data = self._process_batch(le, in_file)\n                self._append_data_to_file(data, out_file)\n                total_data_size += len(data)\n\n        return total_data_size\n\n\nclass GIDSPreprocessor(GID_NYT_BasePreprocessor):\n    DATASET_NAME = 'GIDS'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_train.json')\n    RAW_VAL_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_dev.json')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['GIDS']['dir'], 'gids_test.json')\n    TRAIN_SIZE = 11297\n    VAL_SIZE = 1864\n    TEST_SIZE = 5663\n    PROCESS_BATCH_SIZE = 1024\n\n    def _preprocess_data(self):\n        le = self._get_label_encoder()\n        \n        print(\"Process train dataset\")\n        actual_train_size = self._process_file(\n            le,\n            self.RAW_TRAIN_FILE_NAME,\n            self.get_dataset_file_name('train'),\n            self.TRAIN_SIZE\n        )\n\n        print(\"Process val dataset\")\n        actual_val_size = self._process_file(\n            le,\n            self.RAW_VAL_FILE_NAME,\n            self.get_dataset_file_name('val'),\n            self.VAL_SIZE\n        )\n        \n        print(\"Process test dataset\")\n        actual_test_size = self._process_file(\n            le, \n            self.RAW_TEST_FILE_NAME, \n            self.get_dataset_file_name('test'),\n            self.TEST_SIZE\n        )\n\n        self._save_metadata({\n            'train_size': actual_train_size,\n            'val_size': actual_val_size,\n            'test_size': actual_test_size,\n            'no_relation_label': self.NO_RELATION_LABEL,\n            **self._get_label_mapping(le)\n        })\n\n\nclass NYTPreprocessor(GID_NYT_BasePreprocessor):\n    DATASET_NAME = 'NYT'\n    RAW_TRAIN_FILE_NAME = os.path.join(DATASET_MAPPING['NYT']['dir'], 'riedel_train.json')\n    RAW_TEST_FILE_NAME = os.path.join(DATASET_MAPPING['NYT']['dir'], 'riedel_test.json')\n    TRAIN_SIZE = 570084\n    TEST_SIZE = 172448\n    PROCESS_BATCH_SIZE = 4096 * 4\n\n    def _preprocess_data(self):\n        le = self._get_label_encoder()\n        actual_train_size = 0\n        actual_val_size = 0\n\n        print(\"Process train & val dataset\")\n        batch_count = math.ceil(self.TRAIN_SIZE / self.PROCESS_BATCH_SIZE)\n        with open(self.RAW_TRAIN_FILE_NAME) as in_file,\\\n                open(self.get_dataset_file_name('train'), 'w') as train_file,\\\n                open(self.get_dataset_file_name('val'), 'w') as val_file:\n                    for _ in tqdm(range(batch_count)):\n                        data = self._process_batch(le, in_file)\n                        train_data, val_data = train_test_split(data, shuffle=True, random_state=SEED)\n                        self._append_data_to_file(train_data, train_file)\n                        self._append_data_to_file(val_data, val_file)\n                        actual_train_size += len(train_data)\n                        actual_val_size += len(val_data)\n\n        print(\"Process test dataset\")\n        actual_test_size = self._process_file(\n            le, \n            self.RAW_TEST_FILE_NAME, \n            self.get_dataset_file_name('test'),\n            self.TEST_SIZE\n        )\n\n        self._save_metadata({\n            'train_size': actual_train_size,\n            'val_size': actual_val_size,\n            'test_size': actual_test_size,\n            'no_relation_label': self.NO_RELATION_LABEL,\n            **self._get_label_mapping(le)\n        })\n        \n\ndef get_preprocessor_class(dataset_name: str = DATASET_NAME):\n    return globals()[f'{dataset_name}Preprocessor']\n        \ndef get_preprocessor(dataset_name: str = DATASET_NAME)-> AbstractPreprocessor:\n    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL, use_fast=True)\n    preprocessors_class = get_preprocessor_class(dataset_name)\n    return preprocessors_class(tokenizer)",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": true
   },
   "cell_type": "code",
   "source": "preprocessor = get_preprocessor()\npreprocessor.preprocess_data(reprocess=True)",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7c28c11de594240ac2af7d0b07d47d0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4b6fde25f284460ab564e1a278f7474"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n\n---> Preprocessing SemEval2010Task8 dataset <---\nCreating processed data directory /kaggle/working/data/processed\nProcessing training data\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=8000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb37fbae825c480c8ddb6631d6b43365"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nProcessing test data\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2717.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeeb38648c9343e0900b316364a2e8e9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nEncoding labels to integers\nSplitting train & validate data\nSaving to json files\nCreate metadata file at /kaggle/working/data/processed/metadata.json\nSaving metadata\nCreating secondary files for train data\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=6000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e83b43cb1f214e76ab618e091abe2c17"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nCreating secondary files for test data\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2717.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0ed5798c4dc4beb93bed0e52ea5cf67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nCreating secondary files for val data\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34ba6f81824948e499b6f23883cba94d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nUpdating metadata.json\n---> Done ! <---\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "## Model\n\n### Dataset"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "class GenericDataset(IterableDataset):\n    \"\"\"A generic dataset for train/val/test data for SemEval, GIDS & NYT\"\"\"\n\n    def __init__(self, dataset_name: str, subset: str, batch_size: int, label_transform: str):\n        assert subset in ['train', 'val', 'test']\n        assert label_transform in ['none', 'binary', 'related_only']\n\n        file_name = subset if label_transform == 'none' \\\n            else f'{subset}_{label_transform}'\n\n        preprocessor_class = get_preprocessor_class()\n        with open(METADATA_FILE_NAME) as f:\n            metadata = json.load(f)[dataset_name]\n\n        size = metadata[f'{subset}_related_only_size'] \\\n            if label_transform is 'related_only' \\\n            else metadata[f'{subset}_size']\n\n        self.batch_size = batch_size\n        self.length = math.ceil(size / batch_size)\n        self.fit_in_memory = DATASET_MAPPING[dataset_name]['fit_in_memory']\n        self.file = open(preprocessor_class.get_dataset_file_name(file_name))\n\n    def __del__(self):\n        if self.file:\n            self.file.close()\n\n    def __iter__(self):\n        # if the dataset fits in memory, load at once for better performance\n        if self.fit_in_memory:\n            lines = self.file.readlines()\n        else:\n            lines = self.file\n\n        def get_data():\n            for line in lines:\n                data = json.loads(line)\n                input_data = {k: torch.tensor(v) for k, v in data.items() if k != 'label'}\n                label = torch.tensor(data['label'])\n                yield input_data, label\n\n        return get_data()\n    \n    def __len__(self):\n        return self.length\n\n    def as_batches(self):\n        input_data = []\n        label = []\n        \n        def create_batch():\n            return (\n                {k: torch.stack([x[k] for x in input_data]).cuda() for k in input_data[0].keys()},\n                torch.tensor(label).cuda()\n            )\n        \n        for ip, l in self:\n            input_data.append(ip)\n            label.append(l)\n            if len(input_data) == self.batch_size:\n                yield create_batch()\n                input_data.clear()\n                label.clear()\n\n        yield create_batch()",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "### Torch Lightning Module"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "class BaseClassifier(LightningModule, ABC):\n    def __init__(self, dataset_label_transform: str):\n        super().__init__()\n        assert dataset_label_transform in ['none', 'binary', 'related_only']\n        self.dataset_label_transform = dataset_label_transform\n\n    @abstractmethod\n    def loss_function(self, logits: Tensor, label: Tensor) -> Tensor:\n        \"\"\"\n        Calculate the loss of the model\n        It MUST take care of the last activation layer\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def log_metrics(self, epoch_type: str, logits: Tensor, label: Tensor) -> dict:\n        pass\n\n    def train_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('train')\n\n    def val_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('val')\n\n    def test_dataloader(self) -> DataLoader:\n        return self.__get_dataloader('test')\n\n    def __get_dataloader(self, subset: str) -> DataLoader:\n        batch_size = self.hparams.batch_size\n        dataset = GenericDataset(\n            self.hparams.dataset_name,\n            subset, \n            batch_size, \n            self.dataset_label_transform\n        )\n        return DataLoader(\n            dataset,\n            batch_size=batch_size,\n            num_workers=1\n        )\n\n    def configure_optimizers(self):\n        optimizer = AdamW(\n            [p for p in self.parameters() if p.requires_grad],\n            lr=self.hparams.learning_rate,\n            weight_decay=self.hparams.weight_decay\n        )\n        scheduler = LambdaLR(optimizer, lambda epoch: self.hparams.decay_lr_speed[epoch])\n        return [optimizer], [scheduler]\n    \n    def training_step(self, batch: Tuple[dict, Tensor], batch_nb: int) -> dict:\n        input_data, label = batch\n        logits = self(**input_data)\n\n        loss = self.loss_function(logits, label)\n        log = {'train_loss': loss}\n\n        return {'loss': loss, 'log': log}\n\n    def __eval_step(self, batch:  Tuple[dict, Tensor]) -> dict:\n        input_data, label = batch\n        logits = self(**input_data)\n\n        return {\n            'logits': logits,\n            'label': label,\n        }\n    \n    def validation_step(self, batch: Tuple[dict, Tensor], batch_nb: int) -> dict:\n        return self.__eval_step(batch)\n    \n    def test_step(self, batch: Tuple[dict, Tensor], batch_nb: int) -> dict:\n        return self.__eval_step(batch)\n\n    def __eval_epoch_end(self, epoch_type: str, outputs: Iterable[dict]) -> dict:\n        assert epoch_type in ['test', 'val']\n        \n        logits = torch.cat([x['logits'] for x in outputs]).cpu()\n        label = torch.cat([x['label'] for x in outputs]).cpu()\n        \n        logs = self.log_metrics(epoch_type, logits, label)\n        \n        return {'progress_bar': logs}\n    \n    def validation_epoch_end(self, outputs: Iterable[dict]) -> dict:\n        return self.__eval_epoch_end('val', outputs)\n\n    def test_epoch_end(self, outputs: Iterable[dict]) -> dict:\n        return self.__eval_epoch_end('test', outputs)\n    \n    @staticmethod\n    def plot_confusion_matrix(predicted_label: Tensor, label: Tensor) -> Figure:\n        result = confusion_matrix(label, predicted_label)\n        display = ConfusionMatrixDisplay(result)\n        fig, ax = plt.subplots(figsize=(16, 12))\n        display.plot(cmap=plt.cm.get_cmap(\"Blues\"), ax=ax)\n        return fig\n    \n    def log_confusion_matrix(self, prefix: str, predicted_label: Tensor, label: Tensor):\n        fig = self.plot_confusion_matrix(predicted_label, label)\n        self.logger.experiment.log_image(f'{prefix}_confusion_matrix', fig)\n\n\nclass BinaryClassifier(BaseClassifier):\n\n    def __init__(self, pretrained_language_model, dataset_name, batch_size, learning_rate, decay_lr_speed,\n                 linear_size, dropout_p, activation_function, weight_decay):\n        super().__init__(dataset_label_transform=\"binary\")\n        self.save_hyperparameters()\n        self.thresholds = {}\n\n        self.language_model = AutoModel.from_pretrained(pretrained_language_model)\n        self.dropout = nn.Dropout(p=dropout_p)\n        self.linear = nn.Linear(self.language_model.config.hidden_size, linear_size)\n        self.activation_function = getattr(nn, activation_function)()\n        self.linear_output = nn.Linear(linear_size, 1)\n\n    @staticmethod\n    def yhat_to_label(y_hat: Tensor, threshold: float) -> Tensor:\n        return (y_hat > threshold).long()\n\n    def loss_function(self, logits: Tensor, label: Tensor) -> Tensor:\n        return F.binary_cross_entropy_with_logits(logits, label.float())\n\n    def forward(self, input_ids, attention_mask, sub_start_pos, sub_end_pos,\n                obj_start_pos, obj_end_pos) -> Tensor:\n        language_model_output, = self.language_model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        x = torch.mean(language_model_output, dim=1)\n        x = self.dropout(x)\n        x = self.linear(x)\n        x = self.activation_function(x)\n        x = self.dropout(x) # ??\n        logits = self.linear_output(x).reshape(-1)\n\n        return logits\n    \n    def log_metrics(self, epoch_type: str, logits: Tensor, label: Tensor) -> dict:\n        y_hat = torch.sigmoid(logits)\n        \n        if epoch_type == 'val':\n            self.__find_thresholds(y_hat, label)\n        \n        self.__log_output_distribution(epoch_type, y_hat, label)\n        \n        logs = {\n            f'{epoch_type}_avg_loss': float(self.loss_function(logits, label)),\n            f'{epoch_type}_roc_auc': roc_auc_score(label, y_hat),\n        }\n        \n        for criteria, threshold in self.thresholds.items():\n            prefix = f\"{epoch_type}_{criteria}\"\n            predicted_label = self.yhat_to_label(y_hat, threshold)\n            self.log_confusion_matrix(prefix, predicted_label, label)\n            \n            logs[f'{prefix}_acc'] = accuracy_score(label, predicted_label)\n            logs[f'{prefix}_pre'] = precision_score(label, predicted_label, average='binary')\n            logs[f'{prefix}_rec'] = recall_score(label, predicted_label, average='binary')\n            logs[f'{prefix}_f1'] = f1_score(label, predicted_label, average='binary')\n\n        for k, v in logs.items():\n            self.logger.experiment.log_metric(k, v)\n            \n        return logs\n\n    def __find_thresholds(self, y_hat: Tensor, label: Tensor):\n        \"\"\"\n        Find 3 classification thresholds based on 3 criteria:\n        - The one that yields highest accuracy\n        - The \"best point\" in the ROC curve\n        - The one that yields highest f1\n        The results are logged and stored in self.threshold\n        \"\"\"\n        # best accuracy\n        best_acc = 0\n        best_acc_threshold = None\n        for y in y_hat:\n            y_predicted = self.yhat_to_label(y_hat, threshold=y)\n            acc = accuracy_score(label, y_predicted)\n            if best_acc < acc:\n                best_acc = acc\n                best_acc_threshold = y\n        self.thresholds['best_acc'] = best_acc_threshold\n\n        # ROC curve\n        # https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n        fpr, tpr, thresholds = roc_curve(label, y_hat)\n        gmeans = tpr * (1 - fpr)\n        ix = np.argmax(gmeans)\n        self.thresholds['best_roc'] = thresholds[ix]\n        self.logger.experiment.log_metric(\"best_roc_threshold\", thresholds[ix])\n\n        fig, ax = plt.subplots(figsize=(16, 12))\n        ax.plot([0,1], [0,1], linestyle='--', label='No Skill')\n        ax.plot(fpr, tpr, marker='.', label='Logistic')\n        ax.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n        ax.set_xlabel('False Positive Rate')\n        ax.set_ylabel('True Positive Rate')\n        ax.legend()\n        self.logger.experiment.log_image('roc_curve', fig)\n\n        # precision recall curve\n        # https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n        pre, rec, thresholds = precision_recall_curve(label, y_hat)\n        f1s = 2 * pre * rec / (pre + rec)\n        ix = np.argmax(f1s)\n        self.thresholds['best_f1'] = thresholds[ix]\n        self.logger.experiment.log_metric(\"best_f1_threshold\", thresholds[ix])\n\n        fig, ax = plt.subplots(figsize=(16, 12))\n        no_skill = len(label[label == 1]) / len(label)\n        ax.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n        ax.plot(rec, pre, marker='.', label='Logistic')\n        ax.scatter(rec[ix], pre[ix], marker='o', color='black', label='Best F1')\n        ax.set_xlabel('Recall')\n        ax.set_ylabel('Precision')\n        ax.legend()\n        self.logger.experiment.log_image('pre_rec_curve', fig)\n\n        # log thresholds\n        for k, v in self.thresholds.items():\n            self.logger.experiment.log_metric(f'threshold_{k}', v)\n\n    def __log_output_distribution(self, epoch_type: str, y_hat: Tensor, label: Tensor):\n        \"\"\"\n        Log the distribution of the model output and 3 thresholds with log scale and linear scale\n        \"\"\"\n        y_neg = y_hat[label == 0].numpy()\n        y_pos = y_hat[label == 1].numpy()\n\n        for scale in ['linear', 'log']:\n            fig, ax = plt.subplots(figsize=(16, 12))\n            ax.set_yscale(scale)\n            ax.hist([y_neg, y_pos], stacked=True, bins=100, label=[\"No relation\", \"Related\"])\n            ylim = ax.get_ylim()\n            for k, v in self.thresholds.items():\n                ax.plot([v, v], ylim, linestyle='--', label=f'{k} threshold')\n            ax.legend()\n            self.logger.experiment.log_image(f'{epoch_type}_distribution_{scale}_scale', fig)\n        \n\nclass RelationClassifier(BaseClassifier):\n\n    def __init__(self, pretrained_language_model, dataset_name, batch_size, learning_rate, decay_lr_speed,\n                 dropout_p, weight_decay):\n        super().__init__(dataset_label_transform=\"related_only\")\n        self.save_hyperparameters()\n\n        with open(METADATA_FILE_NAME) as f:\n            num_classes = len(json.load(f)[dataset_name]['label_to_id'])\n\n        self.language_model = AutoModel.from_pretrained(pretrained_language_model)\n        self.dropout = nn.Dropout(p=dropout_p)\n        self.linear = nn.Linear(self.language_model.config.hidden_size, num_classes)\n\n    @staticmethod\n    def logits_to_label(logits: Tensor) -> Tensor:\n        return torch.argmax(logits, dim=-1)\n\n    def loss_function(self, logits: Tensor, label: Tensor) -> Tensor:\n        return F.cross_entropy(logits, label)\n\n    def forward(self, input_ids, attention_mask, sub_start_pos, sub_end_pos,\n                obj_start_pos, obj_end_pos) -> Tensor:\n        language_model_output, = self.language_model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        x = torch.mean(language_model_output, dim=1)\n        x = self.dropout(x)\n        logits = self.linear(x)\n\n        return logits\n\n    def log_metrics(self, epoch_type: str, logits: Tensor, label: Tensor) -> dict:\n        predicted_label = self.logits_to_label(logits)\n        self.log_confusion_matrix(epoch_type, predicted_label, label)\n        \n        logs = {\n            f'{epoch_type}_avg_loss': float(self.loss_function(logits, label)),\n            f'{epoch_type}_acc': accuracy_score(label, predicted_label),\n            f'{epoch_type}_pre_micro': precision_score(label, predicted_label, average='micro'),\n            f'{epoch_type}_rec_micro': recall_score(label, predicted_label, average='micro'),\n            f'{epoch_type}_f1_micro': f1_score(label, predicted_label, average='micro'),\n            f'{epoch_type}_pre_macro': precision_score(label, predicted_label, average='macro'),\n            f'{epoch_type}_rec_macro': recall_score(label, predicted_label, average='macro'),\n            f'{epoch_type}_f1_macro': f1_score(label, predicted_label, average='macro'),\n        }\n        \n        for k, v in logs.items():\n            self.logger.experiment.log_metric(k, v)\n            \n        return logs\n",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Claiming back memory & disk space\n\nSee [this](https://stackoverflow.com/a/61707643/7342188) and [this](https://stackoverflow.com/a/57860310/7342188)"
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "#1 / 0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "binary_classifier = bin_trainer = None",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "relation_classifier = trainer = None",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "gc.collect()\ntorch.cuda.empty_cache()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "bin_logger = None",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "logger = None",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "cell_type": "code",
   "source": "try:\n    shutil.rmtree(CHECKPOINT_DIR)\nexcept:\n    pass",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training binary classifier\n"
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "bin_logger = NeptuneLogger(\n    api_key=NEPTUNE_API_TOKEN,\n    project_name=NEPTUNE_PROJECT_NAME,\n    close_after_fit=False,\n)",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": "https://ui.neptune.ai/hung/bert-relation-extraction/e/BERT-104\n",
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": "NeptuneLogger will work in online mode\n",
     "name": "stderr"
    }
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "GPUS = 1\n\nBIN_MIN_EPOCHS = 1\nBIN_MAX_EPOCHS = 1\n\nbin_trainer = LightningTrainer(\n    gpus=GPUS,\n    min_epochs=BIN_MIN_EPOCHS,\n    max_epochs=BIN_MAX_EPOCHS,\n    default_root_dir=CHECKPOINT_DIR,\n    reload_dataloaders_every_epoch=True, # needed as we loop over a file,\n    deterministic=True,\n    logger=bin_logger,\n)\n",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n",
     "name": "stderr"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "BIN_BATCH_SIZE = 16\nBIN_LEARNING_RATE = 2e-05\nBIN_LEARNING_RATE_DECAY_SPEED = [1, 1, 0.75, 0.5, 0.25, 0.1, 0.075, 0.05, 0.025, 0.01]\n\nBIN_LINEAR_SIZE = 256\n\nBIN_DROPOUT_P = 0.2\nBIN_ACTIVATION_FUNCTION = \"PReLU\"\nBIN_WEIGHT_DECAY = 0.01 # default = 0.01\n\nbinary_classifier = BinaryClassifier(\n    pretrained_language_model=PRETRAINED_MODEL,\n    dataset_name=DATASET_NAME,\n    batch_size=BIN_BATCH_SIZE,\n    learning_rate=BIN_LEARNING_RATE,\n    decay_lr_speed=BIN_LEARNING_RATE_DECAY_SPEED,\n    linear_size=BIN_LINEAR_SIZE,\n    dropout_p=BIN_DROPOUT_P,\n    activation_function=BIN_ACTIVATION_FUNCTION,\n    weight_decay=BIN_WEIGHT_DECAY,\n)\n",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "848242435df54b05a9bd27e956b333db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "_kg_hide-output": true,
    "_kg_hide-input": false,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "bin_trainer.fit(binary_classifier)",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": "\n  | Name                | Type            | Params\n--------------------------------------------------------\n0 | language_model      | DistilBertModel | 66 M  \n1 | dropout             | Dropout         | 0     \n2 | linear              | Linear          | 196 K \n3 | activation_function | PReLU           | 1     \n4 | linear_output       | Linear          | 257   \n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.\n  warnings.warn(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 2 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  warnings.warn(*args, **kwargs)\n",
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f72fb5447847cd97b4aa11de176a55"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'BinaryClassifier' object has no attribute 'log_output_distribution'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-c8f7278293b0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbin_trainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbinary_classifier\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, train_dataloader, val_dataloaders)\u001B[0m\n\u001B[1;32m    977\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    978\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msingle_gpu\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 979\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msingle_gpu_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    980\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    981\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_tpu\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pragma: no-cover\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001B[0m in \u001B[0;36msingle_gpu_train\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    183\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreinit_scheduler_properties\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr_schedulers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_pretrain_routine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtpu_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpu_core_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_pretrain_routine\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m   1137\u001B[0m                                           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval_dataloaders\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                                           \u001B[0mmax_batches\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1139\u001B[0;31m                                           False)\n\u001B[0m\u001B[1;32m   1140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m             \u001B[0;31m# allow no returns from eval\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001B[0m in \u001B[0;36m_evaluate\u001B[0;34m(self, model, dataloaders, max_batches, test_mode)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    341\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_overridden\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'validation_epoch_end'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 342\u001B[0;31m                 \u001B[0meval_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m         \u001B[0;31m# aggregate ddp stats across\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-01db8ccd8db9>\u001B[0m in \u001B[0;36mvalidation_epoch_end\u001B[0;34m(self, outputs)\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mvalidation_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIterable\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 86\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__eval_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'val'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtest_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIterable\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-01db8ccd8db9>\u001B[0m in \u001B[0;36m__eval_epoch_end\u001B[0;34m(self, epoch_type, outputs)\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'label'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 81\u001B[0;31m         \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'progress_bar'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-01db8ccd8db9>\u001B[0m in \u001B[0;36mlog_metrics\u001B[0;34m(self, epoch_type, logits, label)\u001B[0m\n\u001B[1;32m    145\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__find_thresholds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_hat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_output_distribution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_hat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m         logs = {\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    592\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mmodules\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001B[0;32m--> 594\u001B[0;31m             type(self).__name__, name))\n\u001B[0m\u001B[1;32m    595\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    596\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'BinaryClassifier' object has no attribute 'log_output_distribution'"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1152x864 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1152x864 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "bin_trainer.test(binary_classifier)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "bin_logger.experiment.stop()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train relation classifier"
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "logger = NeptuneLogger(\n    api_key=NEPTUNE_API_TOKEN,\n    project_name=NEPTUNE_PROJECT_NAME,\n    close_after_fit=False,\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "MIN_EPOCHS = 1\nMAX_EPOCHS = 1\n\ntrainer = LightningTrainer(\n    gpus=GPUS,\n    min_epochs=MIN_EPOCHS,\n    max_epochs=MAX_EPOCHS,\n    default_root_dir=CHECKPOINT_DIR,\n    reload_dataloaders_every_epoch=True, # needed as we loop over a file,\n    deterministic=True,\n    logger=logger\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 8\nLEARNING_RATE = 2e-05\nLEARNING_RATE_DECAY_SPEED = [1, 1, 0.75, 0.5, 0.25, 0.1, 0.075, 0.05, 0.025, 0.01]\n\nLINEAR_SIZE = 256\n\nDROPOUT_P = 0.2\nACTIVATION_FUNCTION = \"Tanh\"\nWEIGHT_DECAY = 0.01 # default = 0.01\n\nrelation_classifier = RelationClassifier(\n    pretrained_language_model=PRETRAINED_MODEL,\n    dataset_name=DATASET_NAME,\n    batch_size=BATCH_SIZE,\n    learning_rate=LEARNING_RATE,\n    decay_lr_speed=LEARNING_RATE_DECAY_SPEED,\n    # linear_size=LINEAR_SIZE,\n    dropout_p=DROPOUT_P,\n    # activation_function=ACTIVATION_FUNCTION,\n    weight_decay=WEIGHT_DECAY,\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "trainer.fit(relation_classifier)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "trainer.test(relation_classifier)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing 2 classifiers together"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "def test_together(b_classifier: BinaryClassifier, r_classifier: RelationClassifier, dataset_name: str = DATASET_NAME,\n                  bin_batch_size = BIN_BATCH_SIZE, batch_size: int = BATCH_SIZE) -> dict:\n    b_classifier.freeze()\n    r_classifier.freeze()\n\n    true_answer = []\n\n    # run binary classifier\n    print(\"Running binary classifier\")\n    dataset = GenericDataset(dataset_name, subset='test', batch_size=bin_batch_size, label_transform='none')\n    binary_classify_results = { criteria: [] for criteria in b_classifier.thresholds.keys() }\n\n    for input_data, true_label  in tqdm(dataset.as_batches(), total=len(dataset)):\n        # append true answers\n        true_answer += true_label.tolist()\n\n        # run bin classifier\n        logits = b_classifier(**input_data)\n        y_hat = torch.sigmoid(logits)\n        for criteria, threshold in b_classifier.thresholds.items():\n            label = b_classifier.yhat_to_label(y_hat, threshold)\n            binary_classify_results[criteria] += label.tolist()\n\n    # run relation classifier\n    print(\"Running relation classifier\")\n    dataset = GenericDataset(dataset_name, subset='test', batch_size=batch_size, label_transform='none')\n    relation_classify_result = []\n\n    for input_data, true_label  in tqdm(dataset.as_batches(), total=len(dataset)):\n        logits = r_classifier(**input_data)\n        label = r_classifier.logits_to_label(logits) + 1\n        relation_classify_result += label.tolist()\n\n    # combine results\n    print(\"Combining results\")\n    proposed_answer = {}\n    for criteria in b_classifier.thresholds.keys():\n        results = zip(relation_classify_result, binary_classify_results[criteria])\n        final_label = [relation_result if bin_result else 0 for relation_result, bin_result in results]\n        proposed_answer[criteria] = final_label\n\n    # log metric\n    final_metrics = {}\n    for criteria in b_classifier.thresholds.keys():\n        pa = proposed_answer[criteria]\n        \n        final_metrics.update({\n            f'test_combined_{criteria}_acc': accuracy_score(true_answer, pa),\n            f'test_combined_{criteria}_pre_micro': precision_score(true_answer, pa, average='micro'),\n            f'test_combined_{criteria}_rec_micro': recall_score(true_answer, pa, average='micro'),\n            f'test_combined_{criteria}_f1_micro': f1_score(true_answer, pa, average='micro'),\n            f'test_combined_{criteria}_pre_macro': precision_score(true_answer, pa, average='macro'),\n            f'test_combined_{criteria}_rec_macro': recall_score(true_answer, pa, average='macro'),\n            f'test_combined_{criteria}_f1_macro': f1_score(true_answer, pa, average='macro'),\n        })\n        \n        fig = BaseClassifier.plot_confusion_matrix(pa, true_answer)\n        r_classifier.logger.experiment.log_image(f\"test_combined_{criteria}_confusion_matrix\", fig)\n\n    for k, v in final_metrics.items():\n        print(f\"{k}: {v * 100}\")\n\n    for k, v in final_metrics.items():\n        r_classifier.logger.experiment.log_metric(k, v)\n\n    return proposed_answer",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": true
   },
   "cell_type": "code",
   "source": "final_answer = test_together(binary_classifier, relation_classifier)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "trusted": true
   },
   "cell_type": "markdown",
   "source": "## Run the official scorer\n\nSome datasets comes with official scorers. We will run them in this session."
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "class AbstractScorer(ABC):\n    @abstractmethod\n    def score(self, proposed_answer: dict):\n        pass\n\nclass SemEval2010Task8Scorer(AbstractScorer):\n    RESULT_FILE = \"semeval2010_task8_official_score_{}.txt\"\n    PROPOSED_ANSWER_FILE = \"semeval2010_task8_proposed_answer.txt\"\n    SCORER = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'], \"SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl\")\n    FORMAT_CHECKER = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'], \"SemEval2010_task8_scorer-v1.2/semeval2010_task8_format_checker.pl\")\n    ANSWER_KEY = os.path.join(DATASET_MAPPING['SemEval2010Task8']['dir'], \"SemEval2010_task8_testing_keys/TEST_FILE_KEY.TXT\")\n\n    def score(self, proposed_answer: dict):\n\n        # write test_result to file\n        with open(METADATA_FILE_NAME) as f:\n            metadata = json.load(f)\n            id_to_label = {int(k): v for k, v in metadata[DATASET_NAME]['id_to_label'].items()}\n\n        for criteria, answer in proposed_answer.items():\n            result_file = self.RESULT_FILE.format(criteria)\n            i = 8001\n            with open(self.PROPOSED_ANSWER_FILE, \"w\") as f:\n                for r in answer:\n                    f.write(f\"{i}\\t{id_to_label[r]}\\n\")\n                    i += 1\n\n            # call the official scorer\n            os.system(f\"perl {self.FORMAT_CHECKER} {self.PROPOSED_ANSWER_FILE}\")\n            os.system(f\"perl {self.SCORER} {self.PROPOSED_ANSWER_FILE} {self.ANSWER_KEY} > {result_file}\")\n\n            # log the official score\n            with open(result_file) as f:\n                result = f.read()\n                print(f\">>> Binary classifier with {criteria} threshold <<<\")\n                print(result)\n                print(\"\\n\\n\")\n            logger.experiment.log_artifact(result_file)\n\ndef get_official_scorer(dataset_name: str = DATASET_NAME) -> AbstractScorer:\n    return globals().get(dataset_name + \"Scorer\")()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "scorer = get_official_scorer()\nif scorer:\n    scorer.score(final_answer)\nelse:\n    print(\"No official scorer found\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "## Clean up"
  },
  {
   "metadata": {
    "trusted": true,
    "scrolled": false
   },
   "cell_type": "code",
   "source": "logger.experiment.stop()",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}